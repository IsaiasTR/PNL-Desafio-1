{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Alumno:  Isaias Eleuterio Tenorio Retis**"
      ],
      "metadata": {
        "id": "DrNekW-GmmNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consigna del desafío 1**"
      ],
      "metadata": {
        "id": "_zk086J99TgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Fijamos la semilla del generador de números aleatorios\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "tSPcjWj6mYFj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos. Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación.**"
      ],
      "metadata": {
        "id": "iFkctmQum1Tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el dataset fetch_20newsgroups"
      ],
      "metadata": {
        "id": "fm8nN2tnnDcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "_Z2CaHCWnHnI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accedemos a los textos de los documentos\n",
        "documentos = dataset.data"
      ],
      "metadata": {
        "id": "A6sWj5iVv7Sw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accedemos a las etiquetas de clasificación\n",
        "etiquetas = dataset.target\n",
        "etiquetas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKoxCIkXzwi5",
        "outputId": "c3f709f3-e641-4128-e02b-dfe70ed12b84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10,  3, 17, ...,  3,  1,  7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accedemos a los nombres de las categorías\n",
        "categorias = dataset.target_names\n",
        "categorias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls77AnpW0Gna",
        "outputId": "56f2faa0-f4b2-463e-d365-b8b7740aed5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinamos el número total de documentos\n",
        "total_documentos = len(dataset.data)\n",
        "total_documentos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whTkZgM0TXu",
        "outputId": "d9bd9c63-45ef-4a4d-c9b4-bb8bd1072838"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18846"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos las 5 primeras y las 5 últimas etiquetas y sus correspondientes categorías\n",
        "print(\"Primeras 5 etiquetas:\")\n",
        "for i in range(5):\n",
        "    print(f\"Documento {i}: Etiqueta numérica = {etiquetas[i]}, Categoría = {categorias[etiquetas[i]]}\")\n",
        "\n",
        "print(\"\\nÚltimas 5 etiquetas:\")\n",
        "for i in range(total_documentos-5, total_documentos):\n",
        "    print(f\"Documento {i}: Etiqueta numérica = {etiquetas[i]}, Categoría = {categorias[etiquetas[i]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mqPxvsasMCy",
        "outputId": "50b25396-a693-4ca8-9981-e7285239ded7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras 5 etiquetas:\n",
            "Documento 0: Etiqueta numérica = 10, Categoría = rec.sport.hockey\n",
            "Documento 1: Etiqueta numérica = 3, Categoría = comp.sys.ibm.pc.hardware\n",
            "Documento 2: Etiqueta numérica = 17, Categoría = talk.politics.mideast\n",
            "Documento 3: Etiqueta numérica = 3, Categoría = comp.sys.ibm.pc.hardware\n",
            "Documento 4: Etiqueta numérica = 4, Categoría = comp.sys.mac.hardware\n",
            "\n",
            "Últimas 5 etiquetas:\n",
            "Documento 18841: Etiqueta numérica = 13, Categoría = sci.med\n",
            "Documento 18842: Etiqueta numérica = 12, Categoría = sci.electronics\n",
            "Documento 18843: Etiqueta numérica = 3, Categoría = comp.sys.ibm.pc.hardware\n",
            "Documento 18844: Etiqueta numérica = 1, Categoría = comp.graphics\n",
            "Documento 18845: Etiqueta numérica = 7, Categoría = rec.autos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una función para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "    # Con esto eliminamos caracteres no deseados\n",
        "    texto = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\"]+', ' ', texto)\n",
        "    # Con esto reemplazamos espacios múltiples con un solo espacio y quitamos espacios al principio y final\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto"
      ],
      "metadata": {
        "id": "BOAQPpGwPTnB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiamos documentos\n",
        "documentos = [limpiar_texto(doc) for doc in documentos]"
      ],
      "metadata": {
        "id": "_VmHOCyYPXZe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizamos los documentos usando TF-IDF"
      ],
      "metadata": {
        "id": "x8l5etvinLAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizamos = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matriz = vectorizamos.fit_transform(documentos)\n",
        "tfidf_matriz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH8pSKHlnnLu",
        "outputId": "852b2ff5-6741-40c3-9a3d-6eff83e5d743"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<18846x129734 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1225638 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selección aleatoria de 5 documentos"
      ],
      "metadata": {
        "id": "-bVHqcJqnxbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices_aleatorios = random.sample(range(len(documentos)), 5)"
      ],
      "metadata": {
        "id": "YT4GDszcnnlx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora medimos la similaridad entre los documentos seleccionados y el resto. Y por último encontramos los 5 documentos más similares para cada uno de los seleccionados."
      ],
      "metadata": {
        "id": "tAVoSU0tn5II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Medimos la similitud de cada documento seleccionado con el resto\n",
        "resultados_similitud = {}\n",
        "for idx in indices_aleatorios:\n",
        "    documento_tfidf = tfidf_matriz[idx]\n",
        "    similitudes = cosine_similarity(documento_tfidf, tfidf_matriz).flatten()\n",
        "\n",
        "    # Obtener los índices de los documentos más similares\n",
        "    indices_similares = similitudes.argsort()[-6:-1][::-1]  # 5 documentos más similares (sin incluir el propio documento)\n",
        "    resultados_similitud[idx] = indices_similares\n",
        "\n",
        "# Mostramos resultados\n",
        "for idx, similares in resultados_similitud.items():\n",
        "    print(f\"\\nDocumento {idx} (Categoría: {categorias[etiquetas[idx]]})\")\n",
        "    for sim_idx in similares:\n",
        "        if sim_idx < len(documentos):  # Verificar que el índice está dentro del rango\n",
        "            print(f\"  - Documento {sim_idx} (Categoría: {categorias[etiquetas[sim_idx]]}), Similaridad: {cosine_similarity(tfidf_matriz[idx], tfidf_matriz[sim_idx])[0, 0]:.4f}\")\n",
        "            print(f\"    Texto: {documentos[sim_idx][:500]} ...\")  # Mostrar los primeros 500 caracteres del documento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WheEY5ioWk3",
        "outputId": "6849c415-0dff-49e7-ef43-9c72ab732a6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Documento 3648 (Categoría: sci.crypt)\n",
            "  - Documento 9850 (Categoría: sci.crypt), Similaridad: 0.2632\n",
            "    Texto: Read it again yourself, then re apply the admonition you gave to the previous poster to yourself, as well. The first clause is not a condition, it is a reason for explicitly supporting the right WHICH EXISTS, MILITIA OR NOT, that the people have a right to keep and bear arms. This is NOT a right granted by the Constitution, it is a right presumed to exist by default. The Constitution mentioning a right is to prevent the government from removing that right by stating very clearly the government s ...\n",
            "  - Documento 5229 (Categoría: talk.politics.guns), Similaridad: 0.2432\n",
            "    Texto: It appears it is time that this article originally posted by Larry Cipriani last year, and which I saved gets posted again. It offers as good an analysis of the meaning of the Second Amendment, especially regarding the militia clause, as I have seen. I have not seen any rebuttles with similar bone fides... Enjoy. Flames to dev null Begin Enclosed Article THE UNABRIDGED SECOND AMENDMENT by J. Neil Schulman If you wanted to know all about the Big Bang, you'd ring up Carl Sagan, right ? And if you  ...\n",
            "  - Documento 5524 (Categoría: talk.politics.guns), Similaridad: 0.2251\n",
            "    Texto: stuff deleted Ah, clarification by obfuscation. Actually, the words \"A well regulated Milita, being necessary to the security of a free state\" is a present participle, used as an adjective to modify 'militia', which is followed by the main clause of the sentence, the subject being 'the right', the verb 'shall'. It asserts that the right to keep and bear arms is essential for maintaining a milita. The sentence doesn't restrict the right, or state or imply possession of the right by anyone or anyt ...\n",
            "  - Documento 6682 (Categoría: talk.politics.guns), Similaridad: 0.2172\n",
            "    Texto: Though David Sternlight pushes the envelope of credibility by claiming that talk.politics.guns is not the place to discuss guns, or the meaning of the Second Amendment, it seems he would rather post to millions of people out of relative ignorance of the subject than to follow the currently active threads discussing EXACTLY this topic which at least explore the fallacies of his erroneous claim, and at most explode them. Basic fact 1, Mr. Sternlight The RIGHT described is a \"right of the people to ...\n",
            "  - Documento 15183 (Categoría: talk.politics.guns), Similaridad: 0.2103\n",
            "    Texto: Actually, the words \"A well regulated Milita, being necessary to the security of a free state\" is a present participle, used as an adjective to modify 'militia', which is followed by the main clause of the sentence, the subject being 'the right', the verb 'shall'. It asserts that the right to keep and bear arms is essential for maintaining a milita. a free state. Yes, I agree the first half of the amendment does modify the noun militia. But the difinition of modify that applies to how \"well regu ...\n",
            "\n",
            "Documento 819 (Categoría: rec.autos)\n",
            "  - Documento 8883 (Categoría: rec.autos), Similaridad: 0.2420\n",
            "    Texto: Hello again, another question. I just got my hands on 2 quarts of ReadLine Gear Oil at 7 a quart now I need to know how to throw it into my car. I own an 89 NIssan Maxima Se, any Ideas? Can I mix the Oil in there with this stuff, or should I drain first, then only use this stuff. If you know where if there is one the drain plug on the manual transmission on the Maxima is, I would really appreciate any comments. Also have any of you Maxima owners, thied this stuff in your cars? ...\n",
            "  - Documento 12093 (Categoría: rec.autos), Similaridad: 0.1856\n",
            "    Texto: come along since the Mazda MPV. The NISSAN MAXIMA engine paired with the rest of the vehicle seems well engineered. Only the price is ...\n",
            "  - Documento 372 (Categoría: rec.autos), Similaridad: 0.1576\n",
            "    Texto: AutoWeek had an article about the car within the past six weeks. It was the issue with the Diablo VT AWD on the cover. Naturally, I don't remember the date of the issue offhand, but I can check it if anyone is interested. Aamir Qazi ...\n",
            "  - Documento 16043 (Categoría: rec.motorcycles), Similaridad: 0.1439\n",
            "    Texto: I would like to offocially nominate Maxima Chain Wax as another Official tm DoD product of choice. ...\n",
            "  - Documento 13011 (Categoría: rec.autos), Similaridad: 0.1394\n",
            "    Texto: Hi, maybe someone can help me here... I am looking to buy this 1990 Nissan Maxima GXE for CDN 14000 right now. The car has 96000 km or about 60000 miles on it. A typical mileage for 1990 cars seem to be about 70000 km or about 43K mi . The seller just informed me that when he brought the car in for certification he was told that the front break pads and the exhausts had to be replaced to meet the legal standards. He said he will replace the components before selling the car to me. Being copmlete ...\n",
            "\n",
            "Documento 9012 (Categoría: rec.sport.baseball)\n",
            "  - Documento 9810 (Categoría: rec.sport.baseball), Similaridad: 0.2387\n",
            "    Texto: Minor point Shea Stadium was designed as a multi purpose stadium but not with the Jets in mind as the tennant. The New York Football Giants had moved to Yankee Stadium from the Polo Grounds in 1958 and was having problem with stadium management the City did not own Yankee Stadium until 1972 . The idea was to get the Giants to move into Shea. When a deal was worked out between the Giants and the Yankees the new AFL franchise, the New York Titans, approached the City about using the new stadium. T ...\n",
            "  - Documento 6502 (Categoría: rec.sport.baseball), Similaridad: 0.1433\n",
            "    Texto: I'd love to see a Shea Stadium gif. Sean ...\n",
            "  - Documento 14950 (Categoría: rec.sport.baseball), Similaridad: 0.1431\n",
            "    Texto: Me too! And any Yankee Stadium gifs as well, please. Thanx in advance, ...\n",
            "  - Documento 8882 (Categoría: rec.sport.baseball), Similaridad: 0.1400\n",
            "    Texto: While we're on the multipurpose subject, let's not forget Shea, which was designed to accommodate both the Mets Jets. It was the first stadium I think to have the box seats on rollers so they could be oriented at right angles for baseball in parallel for football. Of course, with the Jets gone to Jersey and a truly good football stadium , the Mets are saddled with a multipurpose stadium where, because it's circular, the seats are almost always too far from the action. The Mets announcers Kiner M ...\n",
            "  - Documento 4420 (Categoría: rec.sport.baseball), Similaridad: 0.1355\n",
            "    Texto: And have Jesse Jackson picket the stadium? ...\n",
            "\n",
            "Documento 8024 (Categoría: comp.sys.mac.hardware)\n",
            "  - Documento 5447 (Categoría: comp.sys.mac.hardware), Similaridad: 0.2163\n",
            "    Texto: No. I recently bought an LC II with a 14\" monitor. The monitor comes with the type of power cable that plugs into the switched outlet on the back of most larger Macs. Since the LC II doesn't have one of these outlets, there was an extra standard power cable included with the computer for use with the monitor. But it was in the computer box, not the monitor box. It's not as if the cables are particularly expensive, though. 10 15 at the most. ...\n",
            "  - Documento 9082 (Categoría: comp.sys.mac.hardware), Similaridad: 0.1881\n",
            "    Texto: Well the monitor is consistently the largest power drain on your electric bill when you are looking at your computer set up, especially if you have a large 16\" or greater color monitor. Generally what I do is leave my Mac on all the time, except for the occasional resart or syetem crash, but I turn my monitor off each night before I leave my office. I also turn off After Dark when I do this, since there is no reason to have the screen saver running when there is no picture being displyed on the  ...\n",
            "  - Documento 10739 (Categoría: talk.politics.guns), Similaridad: 0.1716\n",
            "    Texto: Microwaves don't work very well with no electricity Mr Engineer. ...\n",
            "  - Documento 15198 (Categoría: talk.politics.guns), Similaridad: 0.1684\n",
            "    Texto: Ever hear about cutting off the electricity? That was done. How effective is an electric stove then? ...\n",
            "  - Documento 15308 (Categoría: comp.sys.mac.hardware), Similaridad: 0.1652\n",
            "    Texto: There are two approaches 1. If your power cord is the kind that detaches from the back of the monitor most common you can get a replacement power cord that will go from the monitor to the back of the computer. 2. You can get an adpater that connects to the plug end of the existing power cord and provides the proper end that plugs into the back of the computer. ...\n",
            "\n",
            "Documento 7314 (Categoría: rec.motorcycles)\n",
            "  - Documento 6452 (Categoría: rec.motorcycles), Similaridad: 0.1473\n",
            "    Texto: Hi folks. I'm going to be buying my first bike and I'm considering an 82 Honda Ascot FT500 with less than 5K miles. Does this sound like a reasonable choice? Is there anything special I need to know? Thanks. ...\n",
            "  - Documento 2569 (Categoría: rec.motorcycles), Similaridad: 0.1402\n",
            "    Texto: Valve seat wear? Tony ...\n",
            "  - Documento 7667 (Categoría: comp.windows.x), Similaridad: 0.1364\n",
            "    Texto: I am almost done porting XFree86 1.2 to a new piece of display hardware, but have run into a snag I think may be somewhat commonplace, so I'm sending a net feeler. I have a display that is a non interlaced, memory mapped, 1 bit 720x280 display. The server's view of the world, obtained via xwd xwud , seems to be exactly what it should be. However, the displayed version of the framebuffer gives the impression that the server is using scanlines that are too long. After a bit of experimentation, it  ...\n",
            "  - Documento 16999 (Categoría: sci.crypt), Similaridad: 0.1336\n",
            "    Texto: I can think of a couple of ways of guaranteeing authenticity in a one time pad encrytped scheme, though I'm not sure how to prove that what kind of authenicity they provide. An obvious first attempt might be to prepend a truly random unpredictable for Eve block to the message, and then calculate a CRC which included the random starting block and all of the message. This could be encrypted after the message. The problem is, I'm not sure it's impossible to come up with a message that will hash to  ...\n",
            "  - Documento 13151 (Categoría: rec.motorcycles), Similaridad: 0.1253\n",
            "    Texto: I am in the market for a bike and have recently found a 1990 Honda VRF 750 at a dealership. The bike has about 47,000 miles and is around 4500. It has had two previous owners, both employees of the dealership who, I have been told, took very good care of the bike. I have two questions 1 Is this too many miles for a bike? I know this would not be many miles for a car but I am unfamiliar with the life span of bikes. 2 Is this a decent price? I am also unfamilar with prices for used bikes. Is there ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusión**\n",
        "\n",
        "En general, la similaridad entre los documentos es coherente con su contenido y categoría en la mayoria de los casos. Los documentos similares suelen pertenecer a la misma categoría y tratar temas relacionados. Sin embargo, hay excepciones donde la similaridad no es coherente con la categoria o contenido"
      ],
      "metadata": {
        "id": "JCBtJ_celAls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámetros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.**"
      ],
      "metadata": {
        "id": "wtrgrgveG77g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparación del conjunto de datos"
      ],
      "metadata": {
        "id": "jrGZ1vxLHLW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el conjunto de datos\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Dividimos en características y etiquetas\n",
        "X_train, X_test, y_train, y_test = newsgroups_train.data, newsgroups_test.data, newsgroups_train.target, newsgroups_test.target\n",
        "\n",
        "# Vectorización TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "QPbtb7HlHP7a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrwlFx16oriZ",
        "outputId": "db095e77-337b-4b20-8f64-b630a1c62981"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x39115 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 693602 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxPV9QRvptAQ",
        "outputId": "55e241d6-a764-46e2-f4ec-92edd19f67ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7532x39115 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 422138 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos y evaluamos los modelos de Naive Bayes"
      ],
      "metadata": {
        "id": "zqdGc8irHmXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Naïve Bayes Multinomial\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_tfidf, y_train)\n",
        "y_pred_mnb = mnb.predict(X_test_tfidf)\n",
        "\n",
        "# Modelo ComplementNB\n",
        "cnb = ComplementNB()\n",
        "cnb.fit(X_train_tfidf, y_train)\n",
        "y_pred_cnb = cnb.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluación con F1-score macro\n",
        "f1_mnb = f1_score(y_test, y_pred_mnb, average='macro')\n",
        "f1_cnb = f1_score(y_test, y_pred_cnb, average='macro')\n",
        "\n",
        "print(f\"F1-score macro para MultinomialNB: {f1_mnb:.4f}\")\n",
        "print(f\"F1-score macro para ComplementNB: {f1_cnb:.4f}\")\n",
        "\n",
        "# Informe de clasificación detallado\n",
        "print(\"\\nReporte de clasificación para MultinomialNB:\\n\", classification_report(y_test, y_pred_mnb))\n",
        "print(\"\\nReporte de clasificación para ComplementNB:\\n\", classification_report(y_test, y_pred_cnb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiupjS-eHurf",
        "outputId": "24feef07-2d23-46d6-e808-5808f5c5bc14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score macro para MultinomialNB: 0.6512\n",
            "F1-score macro para ComplementNB: 0.6943\n",
            "\n",
            "Reporte de clasificación para MultinomialNB:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.20      0.32       319\n",
            "           1       0.65      0.69      0.67       389\n",
            "           2       0.66      0.60      0.63       394\n",
            "           3       0.61      0.74      0.67       392\n",
            "           4       0.78      0.68      0.73       385\n",
            "           5       0.81      0.76      0.79       395\n",
            "           6       0.78      0.78      0.78       390\n",
            "           7       0.81      0.73      0.77       396\n",
            "           8       0.85      0.75      0.80       398\n",
            "           9       0.91      0.80      0.85       397\n",
            "          10       0.57      0.93      0.71       399\n",
            "          11       0.64      0.79      0.70       396\n",
            "          12       0.71      0.53      0.61       393\n",
            "          13       0.88      0.76      0.81       396\n",
            "          14       0.76      0.74      0.75       394\n",
            "          15       0.38      0.92      0.54       398\n",
            "          16       0.57      0.72      0.64       364\n",
            "          17       0.82      0.79      0.80       376\n",
            "          18       0.87      0.30      0.45       310\n",
            "          19       1.00      0.01      0.02       251\n",
            "\n",
            "    accuracy                           0.68      7532\n",
            "   macro avg       0.74      0.66      0.65      7532\n",
            "weighted avg       0.73      0.68      0.67      7532\n",
            "\n",
            "\n",
            "Reporte de clasificación para ComplementNB:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.44      0.36       319\n",
            "           1       0.70      0.72      0.71       389\n",
            "           2       0.70      0.62      0.66       394\n",
            "           3       0.64      0.70      0.67       392\n",
            "           4       0.76      0.72      0.74       385\n",
            "           5       0.82      0.78      0.80       395\n",
            "           6       0.76      0.74      0.75       390\n",
            "           7       0.81      0.73      0.77       396\n",
            "           8       0.83      0.77      0.80       398\n",
            "           9       0.92      0.83      0.87       397\n",
            "          10       0.85      0.92      0.88       399\n",
            "          11       0.77      0.80      0.79       396\n",
            "          12       0.71      0.55      0.62       393\n",
            "          13       0.83      0.81      0.82       396\n",
            "          14       0.79      0.80      0.79       394\n",
            "          15       0.55      0.89      0.68       398\n",
            "          16       0.58      0.73      0.65       364\n",
            "          17       0.81      0.84      0.82       376\n",
            "          18       0.65      0.42      0.51       310\n",
            "          19       0.45      0.12      0.19       251\n",
            "\n",
            "    accuracy                           0.71      7532\n",
            "   macro avg       0.71      0.70      0.69      7532\n",
            "weighted avg       0.72      0.71      0.71      7532\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los modelos multinominalNB y complementNB mostraron un desempeño similar en la clasificación de textos. La precisión global fue del 68% y del 71% respectivamente. Ambos modelos tienen fortalezas y debilidades en diferentes clases. En general el modelo complementNB mostró un desempeño ligeramente mejor que multinomialNB. Ambos modelos pueden ser considerados buenos para tareas de clasificación de texto."
      ],
      "metadata": {
        "id": "xKEULdGmr2Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajuste de parámetros"
      ],
      "metadata": {
        "id": "3xwuZFMSHyFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros a ajustar para el modelo MultinomialNB\n",
        "param_grid_mnb = {\n",
        "    'alpha': [0.1, 0.5, 1, 2, 5],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "# Parámetros a ajustar para el modelo ComplementNB\n",
        "param_grid_cnb = {\n",
        "    'alpha': [0.1, 0.5, 1, 2, 5],\n",
        "    'norm': [True, False]\n",
        "}\n",
        "\n",
        "# Creamos objetos GridSearchCV para cada modelo\n",
        "grid_search_mnb = GridSearchCV(MultinomialNB(), param_grid_mnb, cv=5, scoring='f1_macro')\n",
        "grid_search_cnb = GridSearchCV(ComplementNB(), param_grid_cnb, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Ajustamos los hiperparámetros utilizando GridSearchCV\n",
        "grid_search_mnb.fit(X_train_tfidf, y_train)\n",
        "grid_search_cnb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Imprimimos los mejores parámetros y el mejor puntaje F1\n",
        "print(\"Mejores parámetros para MultinomialNB:\", grid_search_mnb.best_params_)\n",
        "print(\"Mejor puntaje F1 para MultinomialNB:\", grid_search_mnb.best_score_)\n",
        "\n",
        "print(\"Mejores parámetros para ComplementNB:\", grid_search_cnb.best_params_)\n",
        "print(\"Mejor puntaje F1 para ComplementNB:\", grid_search_cnb.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nM07nE3uYfA",
        "outputId": "d377dab6-dd55-4fc9-e721-84b95a3fe7e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros para MultinomialNB: {'alpha': 0.1, 'fit_prior': False}\n",
            "Mejor puntaje F1 para MultinomialNB: 0.7584425712558112\n",
            "Mejores parámetros para ComplementNB: {'alpha': 0.1, 'norm': True}\n",
            "Mejor puntaje F1 para ComplementNB: 0.7659438101895686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusión**\n",
        "\n",
        "Se encontraron los mejores parámetros para los modelos multinomialNB y complementNB. el modelo complementNB supera al modelo multinomialNB en términos de puntaje F1. Ambos modelos tienen un buen desempeño con un valor pequeño de alpha. la optimización de hiperparámetos mejora la precisión de la clasificación de textos. El modelo complementNB es la mejor opción para clasificación de texto en este caso."
      ],
      "metadata": {
        "id": "J59CNtR0wJ4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.-Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares.La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**.\n"
      ],
      "metadata": {
        "id": "I1R3gRm5IpdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transponemos la matriz documento-término para obtener la matriz término-documento\n",
        "X_tfidf_transposed = X_train_tfidf.T"
      ],
      "metadata": {
        "id": "k7VbJicl99Jg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos los términos (palabras) en el vocabulario\n",
        "terms = vectorizamos.get_feature_names_out()"
      ],
      "metadata": {
        "id": "5DUTxNwS-Bqt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Seleccionamos manualmente las palabras relevantes\n",
        "selected_words = ['computer', 'cars', 'big', 'conference', 'algorithm']"
      ],
      "metadata": {
        "id": "fMvI9OX_-Il7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontramos los índices de las palabras seleccionadas en la matriz término-documento\n",
        "selected_word_indices = []\n",
        "for word in selected_words:\n",
        "    if word in terms:\n",
        "        index = np.where(terms == word)[0][0]\n",
        "        selected_word_indices.append(index)\n",
        "    else:\n",
        "        print(f\"La palabra '{word}' no se encontró en el vocabulario\")\n",
        "\n",
        "# Calculamos la similitud del coseno entre los términos, si hay palabras válidas\n",
        "if selected_word_indices:\n",
        "    similarity_matrix = cosine_similarity(X_tfidf_transposed)\n",
        "\n",
        "    #  Para cada palabra seleccionada, encontrar las 5 palabras más similares\n",
        "    for i, word_index in enumerate(selected_word_indices):\n",
        "        if word_index < similarity_matrix.shape[0]:  # Verificamos que el índice esté en el rango válido\n",
        "            word_similarities = similarity_matrix[word_index]\n",
        "            # Encontramos los índices de las 5 palabras más similares (excluyendo la misma palabra)\n",
        "            similar_word_indices = word_similarities.argsort()[-6:-1][::-1]  # Excluye la palabra misma\n",
        "            similar_words = [terms[idx] for idx in similar_word_indices if idx < len(terms)]\n",
        "\n",
        "            print(f\"Palabra: {selected_words[i]}\")\n",
        "            print(f\"5 palabras más similares: {similar_words}\\n\")\n",
        "        else:\n",
        "            print(f\"Índice de palabra '{selected_words[i]}' fuera de rango\")\n",
        "else:\n",
        "    print(\"No se encontraron palabras seleccionadas en el vocabulario.\")"
      ],
      "metadata": {
        "id": "aL3a3hpCnpPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}